{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset image sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets\n",
    "\n",
    "- Real faces: `ffhq_real_faces`\n",
    "    - 3143 images\n",
    "- Diffusion-generated faces (set 1): `AIS-4SD/StableDiffusion-3-faces-20250203-1545`\n",
    "    - 500 images\n",
    "- Diffusion-generated faces (set 2): `SFHQ-T2I`\n",
    "    - 1724 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of these datasets, we are interested in the image size and whether it's consistent for all images within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_sizes(image_folder_path: Path) -> list:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    image_names = os.listdir(image_folder_path)\n",
    "    image_sizes = []\n",
    "    for i in tqdm(range(len(image_names))):\n",
    "        test_image_path = image_folder_path / image_names[i]\n",
    "        test_img = Image.open(test_image_path)\n",
    "        image_sizes.append(test_img.size)\n",
    "    return image_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_path = Path(\"data/ffhq_real_faces\")\n",
    "image_sizes = get_image_sizes(real_images_path)\n",
    "Counter(image_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images in this dataset have size (1024, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIS-4SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_images_1_path = Path(\"data/AIS-4SD/StableDiffusion-3-faces-20250203-1545\")\n",
    "image_sizes = get_image_sizes(synth_images_1_path)\n",
    "Counter(image_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images in this dataset have size (768, 768)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SFHQ-T2I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_images_2_path = Path(\"data/SFHQ-T2I\")\n",
    "image_sizes = get_image_sizes(synth_images_2_path)\n",
    "Counter(image_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images in this dataset have size (1024, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All 3143 real images have size (1024, 1024)\n",
    "- 1724 of the diffusion-generated images have size (1024, 1024), but 500 of them have size (768, 768)\n",
    "\n",
    "I could upscale the smaller images, but it would be safer (less likely to introduce image artifacts) to reduce the size of the larger images to (768, 768)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will experiment image pre-processing techniques in this notebook as it will be easier to display the images and understand how they are transformed by various functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A recap of PyTorch dataset functionality:\n",
    "- `torch.utils.data.Dataset` stores the samples and their corresponding labels\n",
    "    - Each time it's called, it returns an [input, label] pair\n",
    "    - Pre-processing functions can be defined / called inside this class\n",
    "    - A custom Dataset class must implement three functions: __init__, __len__, and __getitem__\n",
    "- `torch.utils.data.DataLoader` wraps an iterable around the Dataset to enable easy access to the samples   \n",
    "    - Enabled iteration through the dataset in batches\n",
    "    - Provides access to in-built functions for shuffling, parallel processing etc\n",
    "    - Calls the `__getitem__()` function from the Dataset class to create a batch of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is `real`\n",
    "# 1 is `synthetic`\n",
    "\n",
    "image_folder_names_to_labels = {\n",
    "    \"ffhq_real_faces\": 0,\n",
    "    \"AIS-4SD/StableDiffusion-3-faces-20250203-1545\": 1,\n",
    "    \"SFHQ-T2I\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceImageDataset:\n",
    "    def __init__(self):\n",
    "        self.imgs_path = \"data/\"\n",
    "        img_folder_names = list(image_folder_names_to_labels.keys())\n",
    "        self.img_size = (768, 768)\n",
    "\n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
