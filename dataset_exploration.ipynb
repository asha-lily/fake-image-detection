{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset image sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets\n",
    "\n",
    "- Real faces: `ffhq_real_faces`\n",
    "    - 3143 images\n",
    "    - these are all in `png` format\n",
    "- Diffusion-generated faces (set 1): `AIS-4SD/StableDiffusion-3-faces-20250203-1545`\n",
    "    - 500 images\n",
    "    - these are all in `png` format\n",
    "- Diffusion-generated faces (set 2): `SFHQ-T2I`\n",
    "    - 1724 images\n",
    "    - these are all in `jpg` format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of these datasets, we are interested in the image size and whether it's consistent for all images within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_sizes(image_folder_path: Path) -> list:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    image_names = os.listdir(image_folder_path)\n",
    "    image_sizes = []\n",
    "    for i in tqdm(range(len(image_names))):\n",
    "        test_image_path = image_folder_path / image_names[i]\n",
    "        test_img = Image.open(test_image_path)\n",
    "        image_sizes.append(test_img.size)\n",
    "    return image_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_path = Path(\"data/ffhq_real_faces\")\n",
    "image_sizes = get_image_sizes(real_images_path)\n",
    "Counter(image_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images in this dataset have size (1024, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIS-4SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_images_1_path = Path(\"data/AIS-4SD/StableDiffusion-3-faces-20250203-1545\")\n",
    "image_sizes = get_image_sizes(synth_images_1_path)\n",
    "Counter(image_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images in this dataset have size (768, 768)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SFHQ-T2I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_images_2_path = Path(\"data/SFHQ-T2I\")\n",
    "image_sizes = get_image_sizes(synth_images_2_path)\n",
    "Counter(image_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images in this dataset have size (1024, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All 3143 real images have size (1024, 1024)\n",
    "- 1724 of the diffusion-generated images have size (1024, 1024), but 500 of them have size (768, 768)\n",
    "\n",
    "I could upscale the smaller images, but it would be safer (less likely to introduce image artifacts) to reduce the size of the larger images to (768, 768)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will experiment image pre-processing techniques in this notebook as it will be easier to display the images and understand how they are transformed by various functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A recap of PyTorch dataset functionality:\n",
    "- `torch.utils.data.Dataset` stores the samples and their corresponding labels\n",
    "    - Each time it's called, it returns an [input, label] pair\n",
    "    - Pre-processing functions can be defined / called inside this class\n",
    "    - A custom Dataset class must implement three functions: __init__, __len__, and __getitem__\n",
    "- `torch.utils.data.DataLoader` wraps an iterable around the Dataset to enable easy access to the samples   \n",
    "    - Enabled iteration through the dataset in batches\n",
    "    - Provides access to in-built functions for shuffling, parallel processing etc\n",
    "    - Calls the `__getitem__()` function from the Dataset class to create a batch of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder_names_to_labels = {\n",
    "    \"ffhq_real_faces\": \"real\",\n",
    "    \"AIS-4SD/StableDiffusion-3-faces-20250203-1545\": \"synthetic\",\n",
    "    \"SFHQ-T2I\": \"synthetic\"\n",
    "}\n",
    "\n",
    "data_root_dir = Path(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceImageDataset:\n",
    "    def __init__(self, data_root_dir: Path):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_root_dir: Path to directory containing image subdirectories\n",
    "        \"\"\"\n",
    "        self.data_root_dir = data_root_dir\n",
    "        self.img_size = (768, 768)\n",
    "        self.samples = []\n",
    "        self.get_real_images()\n",
    "        self.get_synth_images()\n",
    "\n",
    "    def get_real_images(self):\n",
    "        real_folder_paths = [folder_path for folder_path, class_label in image_folder_names_to_labels.items() if class_label == \"real\"]\n",
    "        for folder_path in real_folder_paths:\n",
    "            for image_name in os.listdir(self.data_root_dir / folder_path):\n",
    "                if image_name.lower().endswith((\".png\", \".jpg\")):\n",
    "                    image_path = self.data_root_dir / folder_path / image_name\n",
    "                    self.samples.append((image_path, 0))\n",
    "\n",
    "    def get_synth_images(self):\n",
    "        synth_folder_paths = [folder_path for folder_path, class_label in image_folder_names_to_labels.items() if class_label == \"synthetic\"]\n",
    "        for folder_path in synth_folder_paths:\n",
    "            for image_name in os.listdir(self.data_root_dir / folder_path):\n",
    "                if image_name.lower().endswith((\".png\", \".jpg\")):\n",
    "                    image_path = self.data_root_dir / folder_path / image_name\n",
    "                    self.samples.append((image_path, 1))\n",
    "    \n",
    "    def apply_transforms(self):\n",
    "        image_transforms = transforms.Compose([\n",
    "            transforms.Resize(size=self.image_size)\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of samples\"\"\"\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \"\"\"\n",
    "        Get one sample\n",
    "        Returns:\n",
    "            image: Transformed image tensor\n",
    "            label: 0 for real, 1 for synthetic\n",
    "        \"\"\"\n",
    "        image_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path)\n",
    "        image = self.apply_transforms(image)\n",
    "        \n",
    "        return image, label\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
